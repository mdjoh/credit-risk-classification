{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a4c9fc",
   "metadata": {},
   "source": [
    "## Install necessary package for Target Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1310f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac3d5d",
   "metadata": {
    "id": "jqm_REd4oouz"
   },
   "source": [
    "## 0. Load Data and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab87fdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6b_BM0Nz9sF",
    "outputId": "4174dd11-33c7-4cb2-a41c-41a65b956b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   UserID             6000 non-null   object\n",
      " 1   Sex                6000 non-null   object\n",
      " 2   PreviousDefault    6000 non-null   int64 \n",
      " 3   FirstName          6000 non-null   object\n",
      " 4   LastName           6000 non-null   object\n",
      " 5   NumberPets         6000 non-null   int64 \n",
      " 6   PreviousAccounts   6000 non-null   int64 \n",
      " 7   ResidenceDuration  6000 non-null   int64 \n",
      " 8   Street             6000 non-null   object\n",
      " 9   LicensePlate       6000 non-null   object\n",
      " 10  BadCredit          6000 non-null   int64 \n",
      " 11  Amount             6000 non-null   int64 \n",
      " 12  Married            6000 non-null   int64 \n",
      " 13  Duration           6000 non-null   int64 \n",
      " 14  City               6000 non-null   object\n",
      " 15  Purpose            6000 non-null   object\n",
      " 16  DateOfBirth        6000 non-null   object\n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 797.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read the provided labeled training data\n",
    "df3 = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1wOhyCnvGeY4jplxI8lZ-bbYN3zLtickf\")\n",
    "df3.info()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df3.drop('BadCredit', axis=1)\n",
    "y = df3['BadCredit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d963922",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "xuuLMYNmPflY",
    "outputId": "39c24ec1-89ff-4573-afbf-7a5886479e9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d0ac2699-082f-499b-99d0-14032b46e5a1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>PreviousDefault</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>NumberPets</th>\n",
       "      <th>PreviousAccounts</th>\n",
       "      <th>ResidenceDuration</th>\n",
       "      <th>Street</th>\n",
       "      <th>LicensePlate</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Married</th>\n",
       "      <th>Duration</th>\n",
       "      <th>City</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>DateOfBirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>236-22-6766</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>Black</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0466 Brown Wall</td>\n",
       "      <td>3-U8282</td>\n",
       "      <td>3329</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>New Roberttown</td>\n",
       "      <td>Household</td>\n",
       "      <td>1970-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>766-20-5986</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Julia</td>\n",
       "      <td>Jones</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6095 Larson Causeway</td>\n",
       "      <td>LWO 912</td>\n",
       "      <td>2996</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Ericmouth</td>\n",
       "      <td>Household</td>\n",
       "      <td>1964-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>744-25-5747</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Abigail</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>293 Michael Divide</td>\n",
       "      <td>715 OQT</td>\n",
       "      <td>2470</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>East Jill</td>\n",
       "      <td>NewCar</td>\n",
       "      <td>1975-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>463-78-3098</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Jones</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>02759 Williams Roads</td>\n",
       "      <td>869 SYK</td>\n",
       "      <td>3745</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Lake Debra</td>\n",
       "      <td>UsedCar</td>\n",
       "      <td>1977-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>414-44-6527</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>William</td>\n",
       "      <td>Shaffer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19797 Turner Rue</td>\n",
       "      <td>48-A601</td>\n",
       "      <td>3549</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>North Judithbury</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>1976-07-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0ac2699-082f-499b-99d0-14032b46e5a1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d0ac2699-082f-499b-99d0-14032b46e5a1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d0ac2699-082f-499b-99d0-14032b46e5a1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           UserID Sex  PreviousDefault  ...              City    Purpose  DateOfBirth\n",
       "3897  236-22-6766   M                0  ...    New Roberttown  Household   1970-04-22\n",
       "5628  766-20-5986   F                0  ...         Ericmouth  Household   1964-06-19\n",
       "1756  744-25-5747   F                0  ...         East Jill     NewCar   1975-02-17\n",
       "2346  463-78-3098   F                0  ...        Lake Debra    UsedCar   1977-02-16\n",
       "2996  414-44-6527   M                0  ...  North Judithbury   Vacation   1976-07-27\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e700cca",
   "metadata": {
    "id": "sdiKKblCo53S"
   },
   "source": [
    "## 1. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2277152a",
   "metadata": {
    "id": "OzHzr_m0Z32Q"
   },
   "source": [
    "Logistic regression will be the algorithm used for this binary classification problem. Because it is a classification problem, Macro F1 score is chosen as the scoring parameter to measure model performance. Macro F1 score is chosen because it reflects both precision and recall metrics and will not mask the poor performance of a prediction class that has low support; thus, this results in the best overall reflection of model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59db50",
   "metadata": {
    "id": "JHx6tgZ2gDTD"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer \n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387535b",
   "metadata": {
    "id": "_YLyv-WtCjFx"
   },
   "source": [
    "The `UserID` feature is hypothesized to not affect the credit risk of an applicant. It is likely a random character sequence that has no value to evaluate the candidacy of a loan applicant. Therefore, this feature will be dropped when building prediction models for this entire question.\n",
    "\n",
    "As part of basic feature engineering, target encoding is used to encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b017f9d",
   "metadata": {
    "id": "DWl5x6Imof_o"
   },
   "outputs": [],
   "source": [
    "# Make a list to store names of columns to drop\n",
    "columns_to_drop = ['UserID']\n",
    "\n",
    "# Get list of categorical features to apply target encoding to\n",
    "categorical_features = list(set(X_train.columns).difference(set(list(\\\n",
    "                                            X_train._get_numeric_data().columns) + columns_to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ebefc0",
   "metadata": {
    "id": "ZK36NSCJOS6X"
   },
   "outputs": [],
   "source": [
    "# Make a feature engineering transformer to drop UserID and apply TargetEncoder\n",
    "fe_transformer = make_column_transformer(\n",
    "                      ('drop', columns_to_drop),\n",
    "                      (TargetEncoder(), categorical_features),\n",
    "                      remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220c827",
   "metadata": {
    "id": "DRhgtT6wNsdd"
   },
   "outputs": [],
   "source": [
    "# Create pipeline with feature engineering transformer and logistic regression\n",
    "pipe1 = make_pipeline(fe_transformer,\n",
    "                    LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc742dcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6cfJ5sD5ELt",
    "outputId": "11891791-8341-4225-dcd4-f46270a06d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.5174, 0.5213, 0.5169, 0.5011, 0.4856, 0.5123, 0.4659, 0.4772, 0.5084, 0.4659] \n",
      "\n",
      "Mean: 0.4972\n",
      "Std. Dev: 0.0206\n",
      "+/-2 std. dev. range within mean: (0.4560, 0.5384)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results\n",
    "cv_scores = cross_val_score(pipe1, X_train, y_train, scoring='f1_macro', cv=10)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores], '\\n')\n",
    "print(f\"Mean: {avg:.4f}\")\n",
    "print(f\"Std. Dev: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d38d43",
   "metadata": {
    "id": "zzlDkxnf5Uqj"
   },
   "source": [
    "The mean Macro F1 score of the baseline model that is obtained via cross-validation is 0.4972."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d21009",
   "metadata": {
    "id": "ugyTS51Ko5vz"
   },
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343098f5",
   "metadata": {
    "id": "Q2AdIOnBAEu_"
   },
   "source": [
    "### Feature Engineering #1:\n",
    "Calculate age from `DateOfBirth` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d6800",
   "metadata": {
    "id": "SIKjaN8naSjQ"
   },
   "outputs": [],
   "source": [
    "# Calculate age in years to 3 decimal places given a date of birth\n",
    "# Age is relative to December 26, 2021\n",
    "\n",
    "from datetime import date, datetime\n",
    "def calculate_age(df):\n",
    "  relative_date = date(2021, 12, 26)\n",
    "  \n",
    "  return df.apply(lambda x: [round((relative_date - datetime.strptime(dob, '%Y-%m-%d').date()).days / 365, 3)\n",
    "                             for dob in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d1461",
   "metadata": {
    "id": "bVpZgfarHPRF"
   },
   "source": [
    "### Feature Engineering #2:\n",
    "A feature that  indicates whether a person is or is not within the typical societal working age range of 25-60 is created. It is likely those under 25 and above 60 will not be working full-time. Thus, it is hypothesized that people within this working age range are more likely to be good loan applicants because they are more likely to have a sufficient employment income to make repayments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52030e7",
   "metadata": {
    "id": "5of4yx5tBDZa"
   },
   "outputs": [],
   "source": [
    "def is_working_age(df):\n",
    "   \n",
    "  def check_working_age(birthdate):\n",
    "    relative_date = date(2021, 12, 26)\n",
    "    age = round((relative_date - datetime.strptime(birthdate, '%Y-%m-%d').date()).days / 365, 3)\n",
    "    return int(age >= 25 and age <= 60)\n",
    "  \n",
    "  return df.apply(lambda x: [check_working_age(dob) for dob in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62cf3b5",
   "metadata": {
    "id": "_4qFMyLXxelU"
   },
   "source": [
    "### Feature Engineering #3:\n",
    "As seen with the baseline model, target encoding is used to encode categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f198775",
   "metadata": {
    "id": "tvtl3osgxZ7n"
   },
   "source": [
    "### Feature Engineering #4:\n",
    "Standard scaling is applied to all features once they are in numerical form in an effort to improve model performance. Scaling of data is\n",
    "required when logistic regression is regularized. Regularization strength is a logistic regrssion hyperparameter that can be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee0364",
   "metadata": {
    "id": "Co4ZbmuBahjm"
   },
   "source": [
    "### Train and Cross-Validate Logistic Regression Model after Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbeab0",
   "metadata": {
    "id": "QrafzVCd0hE1"
   },
   "outputs": [],
   "source": [
    "# Make FunctionTransformers for custom feature engineering functions\n",
    "calculate_age_transformer = FunctionTransformer(calculate_age)\n",
    "working_age_transformer = FunctionTransformer(is_working_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d065dcc",
   "metadata": {
    "id": "GnDq7gwgzooa"
   },
   "outputs": [],
   "source": [
    "# Make a feature engineering transformer to drop UserID and for the first 3 feature engineering steps:\n",
    "# applying calculate_age, is_working_age, and TargetEncoder\n",
    "\n",
    "fe_transformer = make_column_transformer(\n",
    "                      ('drop', columns_to_drop),\n",
    "                      (calculate_age_transformer, ['DateOfBirth']),\n",
    "                      (working_age_transformer, ['DateOfBirth']),\n",
    "                      (TargetEncoder(), categorical_features),\n",
    "                      remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f98c2",
   "metadata": {
    "id": "rrqliROyKd0h"
   },
   "outputs": [],
   "source": [
    "# Create pipeline with feature engineering transformer, standard scaler, and logistic regression\n",
    "pipe2 = make_pipeline(fe_transformer,\n",
    "                      StandardScaler(),\n",
    "                      LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e225086",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9izQilop5nl",
    "outputId": "a4ba0c31-6e95-470f-8047-d9ed0d8ce69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7323, 0.7138, 0.6862, 0.6338, 0.7266, 0.7014, 0.7101, 0.7376, 0.683, 0.7225] \n",
      "\n",
      "Mean: 0.7047\n",
      "Std. Dev: 0.0293\n",
      "+/-2 std. dev. range within mean: (0.6461, 0.7634)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results\n",
    "cv_scores = cross_val_score(pipe2, X_train, y_train, scoring='f1_macro', cv=10)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores], '\\n')\n",
    "print(f\"Mean: {avg:.4f}\")\n",
    "print(f\"Std. Dev: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95258dec",
   "metadata": {
    "id": "Pk0v50I6kwTV"
   },
   "source": [
    "After applying feature engineering, the model mean Macro F1 score improved to 0.7047 from the baseline model mean performance score of 0.4972. However, the standard deviation of the feature engineered model is greater than that of the baseline model suggesting there is increased variability of the prediction ability of the featured engineered model. Feature selection will now be applied in an attempt to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fefaa9",
   "metadata": {
    "id": "PsdD0clko5pz"
   },
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82595a",
   "metadata": {
    "id": "zMbVFIa9NPRg"
   },
   "source": [
    "### High-Cardinality Categorical Features - Street and LicensePlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf50a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOYuLIG0ENjh",
    "outputId": "d6b1f728-1ff0-470c-faaf-ba0f5bd13c0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateOfBirth     3570\n",
       "LastName         907\n",
       "FirstName        568\n",
       "LicensePlate    4799\n",
       "Purpose            8\n",
       "Sex                2\n",
       "Street          4800\n",
       "City              20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the number of unique values of the categorical features of interest\n",
    "X_train[categorical_features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68ff9f",
   "metadata": {
    "id": "05eYZllhB6zi"
   },
   "source": [
    "All instances have a unique value for `Street` and all but one have a unique value for `LicensePlate`. When included, these two features are hypothesized to make the classification model less performant. The model performance will be assessed after dropping these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73fad2d",
   "metadata": {
    "id": "gYjQZjgvCZcf"
   },
   "outputs": [],
   "source": [
    "# Get the updated list of categorical features to apply TargetEncoder to\n",
    "updated_columns_to_drop = ['UserID', 'Street', 'LicensePlate']\n",
    "\n",
    "updated_categorical_features = list(set(X_train.columns).difference(set(list(\\\n",
    "                                            X_train._get_numeric_data().columns) + updated_columns_to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298a232",
   "metadata": {
    "id": "XYDbY4zdGeCq"
   },
   "outputs": [],
   "source": [
    "# Make an updated feature engineering transformer to drop unwanted categorical features and \n",
    "# for the first 3 feature engineering steps (applying calculate_age, is_working_age, and TargetEncoder)\n",
    "\n",
    "updated_fe_transformer = make_column_transformer(\n",
    "                      ('drop', updated_columns_to_drop),\n",
    "                      (calculate_age_transformer, ['DateOfBirth']),\n",
    "                      (working_age_transformer, ['DateOfBirth']),\n",
    "                      (TargetEncoder(), updated_categorical_features),\n",
    "                      remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06fce8",
   "metadata": {
    "id": "uVjNWMzwMLMX"
   },
   "outputs": [],
   "source": [
    "# Create pipeline with updated feature engineering transformer, standard scaler, and logistic regression\n",
    "pipe3 = make_pipeline(updated_fe_transformer,\n",
    "                      StandardScaler(),\n",
    "                      LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4447a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jHq2jd-BSXo",
    "outputId": "e3ed2e0e-2fcf-435f-8329-03e592c32973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7323, 0.7138, 0.6862, 0.6338, 0.7266, 0.7014, 0.7101, 0.7376, 0.683, 0.7225] \n",
      "\n",
      "Mean: 0.7047\n",
      "Std. Dev: 0.0293\n",
      "+/-2 std. dev. range within mean: (0.6461, 0.7634)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results\n",
    "cv_scores = cross_val_score(pipe3, X_train, y_train, scoring = 'f1_macro', cv = 10)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores], '\\n')\n",
    "print(f\"Mean: {avg:.4f}\")\n",
    "print(f\"Std. Dev: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de63fd9",
   "metadata": {
    "id": "qp2CBBUjLF6X"
   },
   "source": [
    "Dropping the `Street` and `LicensePlate` features from the model did not have any effect as identical Macro F1 metrics were obtained. Other feature selection techniques will be attempted to find an optimal subset of features. `Street` and `LicensePlate` will be kept in the dataset in case either or both of these features is in the optimal subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f476f",
   "metadata": {
    "id": "RE959eWvhB2b"
   },
   "source": [
    "### SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5218cc",
   "metadata": {
    "id": "tGYdnZ27hIrA"
   },
   "source": [
    "The SelectKBest method is used to remove features that are poorly correlated with the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09dbfd",
   "metadata": {
    "id": "5ZvTEPIfh5wG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdcd0a5",
   "metadata": {
    "id": "sdYKL47KlNgL"
   },
   "outputs": [],
   "source": [
    "# Make a pipeline with feature engineering transformer, standard scaler, KBest feature selector, and \n",
    "# logistic regression classifier\n",
    "# KBest selector will select the 10 features with the best ANOVA F-value\n",
    "\n",
    "pipe_kbest = make_pipeline(fe_transformer,\n",
    "                      StandardScaler(),\n",
    "                      SelectKBest(score_func=f_classif, k=10),\n",
    "                      LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f761eb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgdtmFAN_TBf",
    "outputId": "d906457e-626a-4103-d5bc-fd496015089d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7287, 0.7026, 0.7051, 0.641, 0.7207, 0.7138, 0.7127, 0.7464, 0.6845, 0.7285] \n",
      "\n",
      "Mean: 0.7084\n",
      "Std. Dev: 0.0276\n",
      "+/-2 std. dev. range within mean: (0.6532, 0.7636)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results\n",
    "cv_scores = cross_val_score(pipe_kbest, X_train, y_train, scoring='f1_macro', cv=10)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores], '\\n')\n",
    "print(f\"Mean: {avg:.4f}\")\n",
    "print(f\"Std. Dev: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8cc293",
   "metadata": {
    "id": "hgPLP3ngpgzn"
   },
   "source": [
    "The SelectKBest method for feature selection gives improved mean results from the model in step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef0d63",
   "metadata": {
    "id": "_pVCvtYkNkDf"
   },
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168eba45",
   "metadata": {
    "id": "4iJaXaocAdf5"
   },
   "source": [
    "Recursive Feature Elimination (RFE) will be used because as a wrapper method, it is able to evaluate model performance and will thoroughly go through testing various feature combinations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9750780",
   "metadata": {
    "id": "2Xhac-40rkvd"
   },
   "outputs": [],
   "source": [
    "# Use RFE to identify the most relevant features\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca586f4f",
   "metadata": {
    "id": "LxCvEfMoBJmg"
   },
   "outputs": [],
   "source": [
    "# Create pipeline with feature engineering transformer, standard scaler, RFE with 10 features to select, \n",
    "# and prediction model\n",
    "\n",
    "pipe_rfe10 = make_pipeline(fe_transformer,\n",
    "                      StandardScaler(),\n",
    "                      RFE(estimator = LogisticRegression(random_state=42), n_features_to_select=10),\n",
    "                      LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e592b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TQCLZM9O5xe",
    "outputId": "93eb6293-e048-406a-abe4-3a2153a30d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7232, 0.7173, 0.7014, 0.641, 0.7207, 0.7163, 0.7101, 0.7438, 0.6845, 0.7225] \n",
      "\n",
      "Mean: 0.7081\n",
      "Std. Dev: 0.0267\n",
      "+/-2 std. dev. range within mean: (0.6547, 0.7615)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results\n",
    "cv_scores = cross_val_score(pipe_rfe10, X_train, y_train, scoring='f1_macro', cv=10)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores], '\\n')\n",
    "print(f\"Mean: {avg:.4f}\")\n",
    "print(f\"Std. Dev: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af8c62",
   "metadata": {
    "id": "bhWIN3oEv2hV"
   },
   "source": [
    "Selecting 10 features results in an increase of 0.0034 in mean Macro F1 score and a standard deviation decrease of 0.0026 when compared to the model from step 2 that was trained with 17 features. Out of curiosity, the model will be retrained by selecting 5 features for RFE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b86f24",
   "metadata": {
    "id": "2nPtbXbsQAx7"
   },
   "outputs": [],
   "source": [
    "# Create pipeline with feature engineering transformer, standard scaler, RFE with 5 features to select,\n",
    "# and prediction model\n",
    "\n",
    "pipe_rfe5 = make_pipeline(fe_transformer,\n",
    "                      StandardScaler(),\n",
    "                      RFE(estimator = LogisticRegression(random_state=42), n_features_to_select=5),\n",
    "                      LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac17778",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBEIUoBKQAx_",
    "outputId": "b3a5779f-8724-4ddd-937c-40ae7aa84ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7215, 0.7098, 0.6821, 0.6381, 0.6854, 0.7014, 0.7163, 0.7207, 0.675, 0.7039] \n",
      "\n",
      "Mean: 0.6954\n",
      "Std. Dev: 0.0246\n",
      "+/-2 std. dev. range within mean: (0.6462, 0.7446)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results\n",
    "cv_scores = cross_val_score(pipe_rfe5, X_train, y_train, scoring='f1_macro', cv=10)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores], '\\n')\n",
    "print(f\"Mean: {avg:.4f}\")\n",
    "print(f\"Std. Dev: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcd16d",
   "metadata": {
    "id": "FCN3LzoCQaZz"
   },
   "source": [
    "Selecting 10 features via either the SelectKBest and RFE methods yields a better mean model performance than the model trained by selecting 5 features via RFE. The model trained that selected 5 features via RFE was less performant than the model from step 2.\n",
    "\n",
    "Models that selected 10 features using the SelectKBest and RFE methods yielded similar mean Macro F1 scores. However, the lower bound of the +/-2 standard deviation range of the model that used the RFE method is higher than that of the model that used the SelectKBest method. Studies have shown that the true performance of a model is closer to the lower bound of the range. Thus, it is hypothesized that using RFE will yield better results in production.\n",
    "\n",
    "Hyperparameter tuning will now be used to try to improve the model performance score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd6828",
   "metadata": {
    "id": "Ff4l2aNKo5fr"
   },
   "source": [
    "## 4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128e6d9",
   "metadata": {
    "id": "BPARxV6SsD9G"
   },
   "source": [
    "### Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92abf8e",
   "metadata": {
    "id": "g2BB61mtslKE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f52c1",
   "metadata": {
    "id": "G1AUKeoNEgJM"
   },
   "source": [
    "Hyperparameters to tune for RFE:\n",
    "\n",
    "* `n_features_to_select`: Number of features to select\n",
    "\n",
    "Hyperparameters to tune for logistic regression:\n",
    "\n",
    "* `penalty`: type of regularization used\n",
    "* `C`: regularization strength where making the value smaller increases the strength\n",
    "* `solver`: optimization algorithm used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad1b0b",
   "metadata": {
    "id": "wf4gvrrKbh_c"
   },
   "outputs": [],
   "source": [
    "# Create pipeline with feature engineering transformer, standard scaler, RFE, and prediction model\n",
    "pipe4 = make_pipeline(fe_transformer,\n",
    "                      StandardScaler(),\n",
    "                      RFE(estimator = LogisticRegression(random_state=42)),\n",
    "                      LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a49887",
   "metadata": {
    "id": "4avGZfEkkveo"
   },
   "source": [
    "Three sets of hyperparameter grids are made because solver algorithms used in logistic regression support different sets of penalties. To try different solver hyperparameters without error, a grid is made for:\n",
    "\n",
    "* `'newton-cg', 'lbfgs', 'sag',` and `'saga'` solvers with `'l2'` and `'none'` as the penalties\n",
    "* `'saga'` solver with `'l1'` as the penality\n",
    "* `'liblinear'` solver with `'l1'` and `'l2'` as the penalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fadd4",
   "metadata": {
    "id": "vk72Xwt2Yiul"
   },
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for solvers that support 'l2' and 'none' penalities\n",
    "gs_params1 = {'rfe__n_features_to_select': [8, 9, 10, 11, 12],\n",
    "          'logisticregression__penalty': ('l2', 'none'),\n",
    "          'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "          'logisticregression__solver': ('newton-cg', 'lbfgs', 'sag', 'saga')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f7e71",
   "metadata": {
    "id": "qGpVJt1vxsQN"
   },
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for saga solver to evaluate how performant model is when penalty='l1'\n",
    "gs_params2 = {'rfe__n_features_to_select': [8, 9, 10, 11, 12],\n",
    "          'logisticregression__penalty': ['l1'],\n",
    "          'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "          'logisticregression__solver': ['saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000d31e",
   "metadata": {
    "id": "aMBxzI4dnka2"
   },
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for liblinear solver which support 'l1' and 'l2' penalties\n",
    "gs_params3 = {'rfe__n_features_to_select': [8, 9, 10, 11, 12],\n",
    "          'logisticregression__penalty': ('l1', 'l2'),\n",
    "          'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "          'logisticregression__solver': ['liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b08f6",
   "metadata": {
    "id": "JTdBVujMpqFw"
   },
   "outputs": [],
   "source": [
    "# Perform GridSearchCV\n",
    "logit_gs = GridSearchCV(pipe4, param_grid=[gs_params1, gs_params2, gs_params3], \n",
    "                        scoring='f1_macro', cv=10, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2223ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBmgea4JsgNw",
    "outputId": "f2b5bc45-daaf-4cda-b107-b30ec39cbe4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('drop',\n",
       "                                                                         'drop',\n",
       "                                                                         ['UserID']),\n",
       "                                                                        ('functiontransformer-1',\n",
       "                                                                         FunctionTransformer(func=<function calculate_age at 0x7f264de72440>),\n",
       "                                                                         ['DateOfBirth']),\n",
       "                                                                        ('functiontransformer-2',\n",
       "                                                                         FunctionTransformer(func=<function is_working_age at 0x7f2645603b00>),\n",
       "                                                                         [...\n",
       "                                                    100, 1000],\n",
       "                          'logisticregression__penalty': ['l1'],\n",
       "                          'logisticregression__solver': ['saga'],\n",
       "                          'rfe__n_features_to_select': [8, 9, 10, 11, 12]},\n",
       "                         {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10,\n",
       "                                                    100, 1000],\n",
       "                          'logisticregression__penalty': ('l1', 'l2'),\n",
       "                          'logisticregression__solver': ['liblinear'],\n",
       "                          'rfe__n_features_to_select': [8, 9, 10, 11, 12]}],\n",
       "             return_train_score=True, scoring='f1_macro')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to training data\n",
    "logit_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7d670",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gsWAEfh4qA2",
    "outputId": "91e41909-b9dd-4cf8-914f-606696771c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'logisticregression__C': 0.001, 'logisticregression__penalty': 'none', 'logisticregression__solver': 'newton-cg', 'rfe__n_features_to_select': 11}'\n",
      "'\n",
      "Best Mean Score: 0.7083\n",
      "Best Mean Std. Dev.: 0.0278\n",
      "+/-2 std. dev. range within mean: (0.6528, 0.7639)\n"
     ]
    }
   ],
   "source": [
    "# Print the hyperparameters, score, standard deviation, and standard deviation range of the \n",
    "# best performing model from GridSearchCV\n",
    "\n",
    "avg = logit_gs.best_score_\n",
    "stddev = logit_gs.cv_results_['std_test_score'][logit_gs.best_index_]\n",
    "\n",
    "print(f\"Best Hyperparameters: {logit_gs.best_params_}'\\n'\")\n",
    "print(f\"Best Mean Score: {avg:.4f}\")\n",
    "print(f\"Best Mean Std. Dev.: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327e83c",
   "metadata": {
    "id": "eK6G4dyw8Lzj"
   },
   "outputs": [],
   "source": [
    "# Function to display in a dataframe cross-validation results sorted by test score rank\n",
    "# This will be used to display GridSearchCV and RandomizedSearchCV results\n",
    "\n",
    "def show_cv_results(cv_results):\n",
    "  df_results = pd.DataFrame(cv_results['params'])\n",
    "  df_results['mean_train_score'] = cv_results['mean_train_score']\n",
    "  df_results['std_train_score'] = cv_results['std_train_score']\n",
    "  df_results['mean_test_score'] = cv_results['mean_test_score']\n",
    "  df_results['std_test_score'] = cv_results['std_test_score']\n",
    "  df_results['rank_test_score'] = cv_results['rank_test_score']\n",
    "\n",
    "  df_results = df_results.sort_values(by='rank_test_score', ascending=True)\n",
    "  return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59937a9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "thyj68kSGY37",
    "outputId": "e2cd71c0-ba4e-4ceb-9c50-9646591c6ad2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-310dfcdb-7eb1-44f4-b641-4948fae4e366\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logisticregression__C</th>\n",
       "      <th>logisticregression__penalty</th>\n",
       "      <th>logisticregression__solver</th>\n",
       "      <th>rfe__n_features_to_select</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.708325</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.708325</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.708325</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.000</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.708325</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.708325</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>8</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>10</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>11</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>10</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>12</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.453054</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows  9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-310dfcdb-7eb1-44f4-b641-4948fae4e366')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-310dfcdb-7eb1-44f4-b641-4948fae4e366 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-310dfcdb-7eb1-44f4-b641-4948fae4e366');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     logisticregression__C  ... rank_test_score\n",
       "278               1000.000  ...               1\n",
       "258               1000.000  ...               1\n",
       "28                   0.001  ...               1\n",
       "153                  1.000  ...               1\n",
       "263               1000.000  ...               1\n",
       "..                     ...  ...             ...\n",
       "280                  0.001  ...             376\n",
       "317                  0.001  ...             376\n",
       "318                  0.001  ...             376\n",
       "282                  0.001  ...             376\n",
       "319                  0.001  ...             376\n",
       "\n",
       "[385 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show test score rank sorted GridSearchCV results\n",
    "best_gs_results = show_cv_results(logit_gs.cv_results_)\n",
    "best_gs_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e34a02",
   "metadata": {
    "id": "3a3rgqx-J1wJ"
   },
   "source": [
    "There are multiple hyperparameter combinations that yield the best mean Macro F1 score of 0.7083 including the combination stored in the `best_params_` attribute. This best mean Macro F1 score is similar to the score obtained in step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ff22e",
   "metadata": {
    "id": "Ai5hxHYPsGo0"
   },
   "source": [
    "### Using Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156eabf7",
   "metadata": {
    "id": "i1Hs7s4us0gG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996dcae",
   "metadata": {
    "id": "0IMFvaS3V5Xa"
   },
   "source": [
    "Randomized search is similar to grid search however, randomly selected values from a continuous distribution will be used for the `n_features_to_select` and `C` hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991b8ef",
   "metadata": {
    "id": "t2_Mdx41WUsr"
   },
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for solvers that support 'l2' and 'none' penalities\n",
    "rs_params1 = {'rfe__n_features_to_select': uniform(0.0, 1.0),\n",
    "          'logisticregression__penalty': ('l2', 'none'),\n",
    "          'logisticregression__C': uniform(0.0001, 10000),\n",
    "          'logisticregression__solver': ('newton-cg', 'lbfgs', 'sag', 'saga')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699fffe",
   "metadata": {
    "id": "ZCGLIHZoWUsv"
   },
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for saga solver to evaluate how performant model is when penalty='l1'\n",
    "rs_params2 = {'rfe__n_features_to_select': uniform(0.0, 1.0),\n",
    "          'logisticregression__penalty': ['l1'],\n",
    "          'logisticregression__C': uniform(0.0001, 10000),\n",
    "          'logisticregression__solver': ['saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2153c",
   "metadata": {
    "id": "JscO6q6TWUsy"
   },
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for liblinear solver which support 'l1' and 'l2' penalties\n",
    "rs_params3 = {'rfe__n_features_to_select': uniform(0.0, 1.0),\n",
    "          'logisticregression__penalty': ('l1', 'l2'),\n",
    "          'logisticregression__C': uniform(0.0001, 10000),\n",
    "          'logisticregression__solver': ['liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccb93e",
   "metadata": {
    "id": "VMsXDllAWUs0"
   },
   "outputs": [],
   "source": [
    "# Combine the two hyperparameter grids into a list\n",
    "rs_params = [rs_params1, rs_params2, rs_params3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb901b8c",
   "metadata": {
    "id": "nTW9h8dDi6eg"
   },
   "outputs": [],
   "source": [
    "# Perform RandomizedSearchCV \n",
    "logit_rs = RandomizedSearchCV(pipe4, param_distributions=[rs_params1, rs_params2, rs_params3], \n",
    "                              n_iter=1000, scoring='f1_macro', cv=10, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535a2b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnD4Y0dpBIt8",
    "outputId": "8235e3e6-3daa-4260-86d4-79b1d91af451"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('drop',\n",
       "                                                                               'drop',\n",
       "                                                                               ['UserID']),\n",
       "                                                                              ('functiontransformer-1',\n",
       "                                                                               FunctionTransformer(func=<function calculate_age at 0x7f264de72440>),\n",
       "                                                                               ['DateOfBirth']),\n",
       "                                                                              ('functiontransformer-2',\n",
       "                                                                               FunctionTransformer(func=<function is_working_age at 0x7f2645603b...\n",
       "                                         'rfe__n_features_to_select': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f264450e350>},\n",
       "                                        {'logisticregression__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f26447d9850>,\n",
       "                                         'logisticregression__penalty': ('l1',\n",
       "                                                                         'l2'),\n",
       "                                         'logisticregression__solver': ['liblinear'],\n",
       "                                         'rfe__n_features_to_select': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f26447d9b10>}],\n",
       "                   return_train_score=True, scoring='f1_macro')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to training data\n",
    "logit_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26e2c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2tbcHFf2W-i",
    "outputId": "ac7bfc33-22a7-4ebb-c5c3-37c6708cf008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'logisticregression__C': 9465.876175501207, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs', 'rfe__n_features_to_select': 0.1408325471180527}'\n",
      "'\n",
      "Best Mean Score: 0.7821\n",
      "Best Mean Std. Dev.: 0.0330\n",
      "+/-2 std. dev. range within mean: (0.7162, 0.8481)\n"
     ]
    }
   ],
   "source": [
    "# Print the hyperparameters, score, standard deviation, and standard deviation range of the \n",
    "# best performing model from RandomizedSearchCV\n",
    "\n",
    "avg = logit_rs.best_score_\n",
    "stddev = logit_rs.cv_results_['std_test_score'][logit_rs.best_index_]\n",
    "\n",
    "print(f\"Best Hyperparameters: {logit_rs.best_params_}'\\n'\")\n",
    "print(f\"Best Mean Score: {avg:.4f}\")\n",
    "print(f\"Best Mean Std. Dev.: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77503637",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "zP0J3OnB2W-m",
    "outputId": "be3b8d5a-95e3-456d-d2c1-29230cde1143"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4967bb82-8d92-4a28-b9fe-64b9713ab391\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logisticregression__C</th>\n",
       "      <th>logisticregression__penalty</th>\n",
       "      <th>logisticregression__solver</th>\n",
       "      <th>rfe__n_features_to_select</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>135.764355</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>0.782894</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.782148</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3953.554567</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.118956</td>\n",
       "      <td>0.782894</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.782148</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>7913.923427</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.151762</td>\n",
       "      <td>0.782952</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.782148</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>7074.127874</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.169084</td>\n",
       "      <td>0.782894</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.782148</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>8664.842155</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.144419</td>\n",
       "      <td>0.782894</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.782148</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>3725.784953</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>777.138983</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>7072.568959</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.032493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>8724.222369</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>1113.965448</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4967bb82-8d92-4a28-b9fe-64b9713ab391')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4967bb82-8d92-4a28-b9fe-64b9713ab391 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4967bb82-8d92-4a28-b9fe-64b9713ab391');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     logisticregression__C  ... rank_test_score\n",
       "696             135.764355  ...               1\n",
       "162            3953.554567  ...               1\n",
       "432            7913.923427  ...               1\n",
       "166            7074.127874  ...               1\n",
       "427            8664.842155  ...               1\n",
       "..                     ...  ...             ...\n",
       "854            3725.784953  ...             996\n",
       "847             777.138983  ...             997\n",
       "339            7072.568959  ...             998\n",
       "885            8724.222369  ...             999\n",
       "878            1113.965448  ...            1000\n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show test score rank sorted RandomizedSearchCV results\n",
    "best_rs_results = show_cv_results(logit_rs.cv_results_)\n",
    "best_rs_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7461f31",
   "metadata": {
    "id": "So87BO5R5vly"
   },
   "source": [
    "As the case with GridSearchCV results, RandomizedSearchCV returns multiple hyperparameter combinations that yield the best mean Macro F1 score including the combination stored in the `best_params_` attribute. The best hyperparameter combination from RandomizedSearchCV produced a better mean Macro F1 score (0.7821) than any of the previously trained models. Furthermore, the lower bound of the +/-2 standard deviation range of this model (0.7162) is greater than the best mean Macro F1 score (0.7084) from step 3. This suggests that hyperparameter tuning via RandomizedSearchCV was effective and in production, the model with the best hyperparameter combination should yield a Macro F1 score that is better than the previous best mean score of 0.7084.\n",
    "\n",
    "Each step has improved the mean Macro F1 score of the logistic regression model (0.4972 -> 0.7047 -> 0.7084 -> 0.7821). However, it remains to be seen how the best performing model produced in this step will fare on unseen data. The best performing model from RandomizedSearchCV will now be deployed on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0322976",
   "metadata": {
    "id": "Te9gGGLEpXRG"
   },
   "source": [
    "## 5. Performance Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c75f85",
   "metadata": {
    "id": "bkRaWS01vRJp"
   },
   "source": [
    "### Evaluate Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a871162",
   "metadata": {
    "id": "sTBo09Gxlwsw"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686da96",
   "metadata": {
    "id": "8LAvtDDsy_7f"
   },
   "outputs": [],
   "source": [
    "# Make predictions on test data using model with the best hyperparameter combination \n",
    "# obtained via RandomSearchCV in step 4\n",
    "y_pred = logit_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30332445",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orD3TuxCzA7v",
    "outputId": "c08c1c69-2c17-44ac-88cc-8b78e3e60e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[956  35]\n",
      " [ 89 120]] \n",
      "\n",
      "Test Set Macro F1 Score: 0.7992\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix and performance metric\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm, '\\n')\n",
    "print(f\"Test Set Macro F1 Score: {f1_score(y_test, y_pred, average='macro'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a327a6",
   "metadata": {
    "id": "thk4FaZZwtb_"
   },
   "source": [
    "When deployed on the test set, the model produced a greater Macro F1 score (0.7992) than the best mean score (0.7821) from step 4. While greater, the test performance score is within two standard deviations of the mean score of the best performing model implying that the scores are similar. The similar Macro F1 scores resulting from the training and test sets suggest that how this model performs during training is a valid reflection of how it would perform in production to predict whether a loan applicant has good or bad risk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
